# Vectorless Document Processing Integration

## ğŸ“„ Overview

The provided `vectorless-main/` folder contains a complete document processing system that can handle 30+ PDFs with intelligent chunking **without RAG**.

This guide explains how to use it alongside your main research application.

---

## ğŸ—ï¸ What is Vectorless?

Vectorless is a document processing system that:
- âœ… Processes PDFs without vector databases
- âœ… Intelligent chunking (1200 chars/chunk, 10% overlap)
- âœ… Maintains context across chunks
- âœ… Tracks citations with `citationKey`
- âœ… Handles 30+ documents efficiently
- âœ… Parses AlphaSense transcripts
- âœ… SQLite storage (no external dependencies)

---

## ğŸš€ Setup Vectorless (Optional)

If you need to process PDF documents or transcripts, run Vectorless in parallel:

### 1. Navigate to Vectorless

```bash
cd vectorless-main
```

### 2. Install Dependencies

```bash
pnpm install
```

### 3. Setup Database

```bash
# Create .env.local file
echo "DATABASE_URL=file:./.data/vectorless.db" > .env.local
echo "OPENAI_API_KEY=your-openai-api-key-here" >> .env.local
echo "FILE_STORAGE_DIR=./.data/uploads" >> .env.local

# Run migrations
pnpm db:migrate
```

### 4. Start Vectorless

```bash
# Option A: Start everything
pnpm dev

# Option B: Start separately
# Terminal 1:
pnpm dev:web

# Terminal 2:
pnpm dev:worker
```

### 5. Access Vectorless

Open: **http://localhost:3000**

---

## ğŸ”„ Two-App Workflow

### Setup

You'll run two apps simultaneously:

| App | Purpose | Port | URL |
|-----|---------|------|-----|
| **Open Deep Research** | Web research, CDD reports | 13000 | http://localhost:13000 |
| **Vectorless** | PDF processing, document analysis | 3000 | http://localhost:3000 |

### Workflow

#### For Web-Only Research (No PDFs)

Use **Open Deep Research** (port 13000):
1. Ask research question
2. Answer clarifying questions
3. Get CDD report with web sources
4. Export as PDF/MD

#### For PDF-Based Research

Use **Vectorless** (port 3000):
1. Create research run
2. Upload PDFs (30+ documents)
3. Upload transcripts (AlphaSense format)
4. Ask clarifying questions
5. Generate research plan
6. Launch deep research
7. Edit report sections
8. Export with citations to uploaded docs

#### For Hybrid Research (Web + PDFs)

1. **Start with Vectorless**:
   - Upload documents
   - Process with worker
   - Extract key findings

2. **Switch to Open Deep Research**:
   - Use insights from PDFs as context
   - Perform web research for additional sources
   - Generate comprehensive CDD report
   - Combine PDF citations with web sources

---

## ğŸ“Š Vectorless Features

### Document Processing

**Supported Formats**:
- âœ… PDF (primary)
- âœ… TXT transcripts
- âœ… AlphaSense interview transcripts

**Processing Pipeline**:
```
PDF Upload â†’ Queue (pending status) â†’
Ingest Worker â†’ Extract pages â†’
Adaptive Chunking â†’ Store chunks â†’
Create citation keys â†’ Mark ready
```

**Chunking Algorithm**:
```typescript
{
  maxCharsPerChunk: 1200,
  overlapRatio: 0.1,
  minChunkChars: 250
}
```

### Citation System

Every chunk gets a unique `citationKey`:
- PDFs: `DOC-{documentId}-{chunkOrder}`
- Transcripts: `TRANS-{transcriptId}-{segmentOrder}`

Example:
```
DOC-a1b2c3-0   â†’ First chunk of document a1b2c3
DOC-a1b2c3-1   â†’ Second chunk
TRANS-x9y8-0   â†’ First segment of transcript
```

### Transcript Parsing

Handles AlphaSense format:
```
Speaker Name: This is what they said...
Another Speaker: This is their response...
```

Parses into:
- Speaker identification
- Turn order
- Timestamps (estimated)
- Searchable segments

---

## ğŸ”— Integration Options

### Option 1: Use Separately (Current Setup)

**Pros**:
- âœ… No code changes needed
- âœ… Apps are independent
- âœ… Can run on different machines
- âœ… Easy to maintain

**Cons**:
- âš ï¸ Need to switch between interfaces
- âš ï¸ Manual data transfer
- âš ï¸ Two separate systems

**Best For**:
- Testing PDF processing
- Working with existing PDFs
- Transcript analysis
- Document-heavy research

### Option 2: API Integration (Future)

Integrate Vectorless into main app via API:

1. **Start Vectorless as microservice**:
```bash
cd vectorless-main
pnpm dev:web  # Runs on port 3000
```

2. **Call from main app**:
```typescript
// In app/(chat)/api/chat/route.ts
const response = await fetch('http://localhost:3000/api/ingest/upload', {
  method: 'POST',
  body: formData
});
```

3. **Use document IDs** in research prompts

### Option 3: Full Merge (Advanced)

Merge Vectorless packages into main monorepo:

1. Copy packages:
```bash
cp -r vectorless-main/packages/* packages/
```

2. Update package.json workspaces
3. Install dependencies
4. Create upload endpoints in main app
5. Run ingest worker alongside main app

---

## ğŸ“ Vectorless Architecture

### Directory Structure

```
vectorless-main/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ web/                    # Next.js research UI
â”‚   â”‚   â”œâ”€â”€ app/api/
â”‚   â”‚   â”‚   â”œâ”€â”€ ingest/         # PDF upload
â”‚   â”‚   â”‚   â”œâ”€â”€ transcripts/    # Transcript upload
â”‚   â”‚   â”‚   â””â”€â”€ research/       # Run management
â”‚   â”‚   â””â”€â”€ lib/
â”‚   â”‚       â””â”€â”€ orchestrator.ts # Clarify/Rewrite/Research
â”‚   â”‚
â”‚   â””â”€â”€ ingest-worker/          # Background processor
â”‚       â””â”€â”€ src/index.ts        # PDF chunking worker
â”‚
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ core/                   # Shared utilities
â”‚   â”‚   â”œâ”€â”€ chunking.ts         # Adaptive chunking algorithm
â”‚   â”‚   â”œâ”€â”€ pdf.ts              # PDF extraction (pdf-parse)
â”‚   â”‚   â”œâ”€â”€ storage.ts          # File storage (.data/uploads)
â”‚   â”‚   â”œâ”€â”€ transcript-parser.ts # AlphaSense parser
â”‚   â”‚   â”œâ”€â”€ orchestrator.ts     # Prompt builders
â”‚   â”‚   â””â”€â”€ duckdb.ts           # Analytics (optional)
â”‚   â”‚
â”‚   â”œâ”€â”€ db/                     # Prisma + SQLite
â”‚   â”‚   â”œâ”€â”€ prisma/schema.prisma
â”‚   â”‚   â””â”€â”€ src/index.ts
â”‚   â”‚
â”‚   â””â”€â”€ ui/                     # Shared components
â”‚
â””â”€â”€ .data/                      # Storage
    â”œâ”€â”€ uploads/                # PDFs, transcripts
    â”œâ”€â”€ vectorless.db           # SQLite database
    â””â”€â”€ duckdb/                 # Analytics DB
```

### Database Schema

Key tables:
- `ResearchRun` - Research sessions
- `Document` - Uploaded files
- `Chunk` - Document chunks with citation keys
- `Source` - Bibliography entries
- `Citation` - Inline citation tracking
- `InterviewTranscript` - Parsed transcripts
- `ProgressEvent` - Activity timeline
- `MethodologyEntry` - Audit trail

---

## ğŸ’¡ Use Cases

### When to Use Main App (port 13000)

**Best for**:
- Web research
- Market analysis
- Competitive intelligence
- Quick CDD reports
- Public information research

**Example Questions**:
- "Research the SaaS CRM market"
- "Analyze competitive landscape for fintech"
- "Evaluate PE opportunity in healthcare IT"

### When to Use Vectorless (port 3000)

**Best for**:
- Processing confidential PDFs
- Analyzing 10-K filings
- Transcript analysis
- Document-heavy due diligence
- Internal company documents

**Example Workflows**:
- Upload 30 10-K filings â†’ Extract financials
- Process interview transcripts â†’ Find insights
- Analyze internal memos â†’ Summarize themes

### Hybrid Approach

**Best for**:
- Comprehensive CDD combining web + internal docs
- PE deal flow research
- Investment committee materials

**Workflow**:
1. Upload PDFs to Vectorless
2. Extract key findings from documents
3. Use findings as context in main app
4. Perform web research to supplement
5. Generate combined CDD report

---

## ğŸ”§ Vectorless API Endpoints

If you want to integrate programmatically:

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/api/research/run` | POST | Create research run |
| `/api/ingest/upload` | POST | Upload PDF |
| `/api/transcripts/upload` | POST | Upload transcript |
| `/api/research/run/[id]/clarify` | POST | Ask clarifying questions |
| `/api/research/run/[id]/rewrite` | POST | Generate research plan |
| `/api/research/run/[id]/start` | POST | Launch deep research |
| `/api/research/run/[id]/status` | GET | Poll research status |
| `/api/research/run/[id]/sources` | GET | Get bibliography |
| `/api/research/run/[id]/export/markdown` | GET | Export as Markdown |
| `/api/research/run/[id]/export/pdf` | GET | Export as PDF |

---

## ğŸ“– Example: Processing PDFs with Vectorless

### 1. Create Research Run

```typescript
POST http://localhost:3000/api/research/run
{
  "title": "SaaS Market Analysis",
  "brief": "Analyze the B2B SaaS accounting market for PE investment"
}

Response:
{
  "run": {
    "id": "clxxx...",
    "title": "SaaS Market Analysis",
    "status": "CLARIFYING"
  }
}
```

### 2. Upload Documents

```bash
curl -X POST http://localhost:3000/api/ingest/upload \
  -F "file=@company-10k.pdf" \
  -F "runId=clxxx..."
```

### 3. Wait for Processing

Check status:
```bash
GET http://localhost:3000/api/research/run/clxxx...
```

When `status: "ready"`, documents are processed.

### 4. Ask Clarifying Questions

```bash
POST http://localhost:3000/api/research/run/clxxx.../clarify
```

Returns clarifying questions to answer.

### 5. Launch Research

```bash
POST http://localhost:3000/api/research/run/clxxx.../start
```

Launches OpenAI Deep Research with document context.

### 6. Poll for Completion

```bash
GET http://localhost:3000/api/research/run/clxxx.../status
```

When complete, report sections are generated.

### 7. Export Report

```bash
GET http://localhost:3000/api/research/run/clxxx.../export/pdf
```

Downloads PDF with citations to uploaded documents.

---

## ğŸ¯ Decision Guide

### Use Main App If:
- âœ… Researching public information
- âœ… Need fast CDD reports (2-5 min)
- âœ… Sources are web-based
- âœ… Don't have confidential PDFs
- âœ… Want purple-themed UI
- âœ… Need quick exports

### Use Vectorless If:
- âœ… Have 10+ PDFs to process
- âœ… Need transcript analysis
- âœ… Want citation keys to docs
- âœ… Analyzing confidential materials
- âœ… Building document database
- âœ… Need methodology audit trail

### Use Both If:
- âœ… Conducting comprehensive CDD
- âœ… Combining internal docs + web research
- âœ… Building investment committee materials
- âœ… Need maximum research depth

---

## ğŸ” Data Privacy

### Main App
- Web sources only
- Citations to public URLs
- No persistent document storage
- Session-based data

### Vectorless
- Local file storage (`.data/uploads/`)
- SQLite database (`.data/vectorless.db`)
- No external services (except OpenAI)
- Full data control

---

## ğŸ“š Learning Resources

### Vectorless Documentation

See `vectorless-main/README.md` for:
- Complete setup guide
- API endpoint documentation
- Database schema
- Workflow examples

### Code References

Key files to understand:

**Chunking**:
- `vectorless-main/packages/core/src/chunking.ts`
- Adaptive algorithm with overlap
- Token-agnostic (character-based)

**PDF Processing**:
- `vectorless-main/packages/core/src/pdf.ts`
- Uses pdf-parse library
- Extracts text per page

**Citation Tracking**:
- `vectorless-main/apps/ingest-worker/src/index.ts`
- Generates unique citation keys
- Links chunks to sources

**Transcript Parsing**:
- `vectorless-main/packages/core/src/transcript-parser.ts`
- AlphaSense format support
- Speaker turn detection

---

## âœ¨ Summary

**You have two powerful tools**:

1. **Open Deep Research (port 13000)** â­ MAIN APP
   - Web research
   - CDD reports
   - Fast turnaround
   - Purple theme
   - Clarifying questions
   - Export options

2. **Vectorless (port 3000)** ğŸ“„ OPTIONAL
   - PDF processing
   - Transcript analysis
   - Document chunking
   - Citation tracking
   - SQLite storage

**Use main app for 90% of research needs.**

**Add Vectorless only if you need PDF processing.**

---

**Status**: Both systems are ready to use  
**Main App**: âœ… Running on port 13000  
**Vectorless**: ğŸ“¦ Available in `vectorless-main/` folder

---

**Need help?** See `COMPLETE_SETUP_GUIDE.md` for full instructions.

